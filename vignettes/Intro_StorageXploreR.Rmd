---
title: "Introduction to StorageXploreR"
author: Lionel Morgado
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to StorageXploreR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(StorageXploreR)
```


# Introduction

Over time, organizations can accumulate large amounts of data following poor storage standards.
For example, it is common to find in legacy data, multiple copies of the exact same file spread 
all over the storage, the same data stored in different file formats, or files in formats which are
suboptimal for storage.
This can rise adverse situations, such as a lack of storage space or add unnecessary storage costs.
 

StorageXploreR provides a set of functions to scan data storage units and quickly create a utilization
profile to facilitate downstream optimization and standardization. Using file attributes such as the 
name, extension, format and size, it enables the detection of multi-copy and name-related files as 
candidates for potential removal or format optimization.

This vignette shows some common ways in which the functions in this package can
be used. It is however not exhaustive and will not show every argument of every
function. You can view the documentation of a function by adding a `?` in front
of it (e.g. `?plot_donut`). This allows to get a more detailed description of the functions and all their
arguments. Additional examples of how the functions in this package can be used are also available.


# Installation

The package can be installed from github.
```{r install_package, eval=FALSE}
install_github("LionelMorgado/StorageXploreR")
```


The package also needs to be loaded every time `R` is restarted.
```{r Load package, message=FALSE}
library(StorageXploreR)
```


# Scan storage

The package provides a function to scan data storage units. After a successfull execution, it creates an output file that can be used for further inspection of the results.
Detecting all files and their respective sizes in a given directory is possible by using:
```{r scan_storage, eval=FALSE}
scan_storage("/mnt/d/")
```
Please keep in mind that scanning storage units with very large amounts of data can be very time consuming. Therefore, it is recommended to reuse the scan output file when no meaningful changes in the storage are expected.

# Load data
To load data from a previous storage scan, run:
```{r load_data, eval=FALSE}
scan_file = "/mnt/d/StorageXploreR-2025-01-10_20h18m.txt"
dataset = read.table(scan_file, header=TRUE, sep="\t")
```
```{r knit1, include = FALSE}
scan_file = "D:/Stuff/GITHUBPortfolio/Storage/Storage_HUBOrganoids/RESULTS/WDrive_storage.txt"
dataset = read.table(scan_file, header=TRUE, sep="\t")
```


# Basic data filtering: include/exclude subsets
It is possible to focus on specific directories by selecting or removing subsets with the functions include and exclude.

##Include data
This allows to select a subset of the items that start with a given tag, such as a common root data directory:
```{r include_data, eval=FALSE}
inc_flag = include(dataset[,2],"./CNV/CNAprofiles" )
dataset = dataset[inc_flag,]
```

##Exclude data
This allows to exclude a subset of the items that start with a given tag, such as a common root data directory: 
```{r exclude_data, eval=FALSE}
exc_flag = exclude(dataset[,2],"./CNV/CNAprofiles" )
dataset = dataset[exc_flag,]
```


# Parsers
A simple but powerfull set of functions to parse paths and file names.  
  
Given that there is currently no wide spread consensus about the file naming terminology, here we use the following:  
* Path: string of characters used to uniquely identify a location in a directory structure, where folders are separated by slash ("/");  
* Name: name of the file without the extension;  
* Extension: last portion of the file name that typically comes after a period and is made up of three or four alphanumeric characters that identify the file's format;  
* Full name: concatenation of the name and extension with a dot in between.  
  
For example, in "/mnt/d/StorageXploreR_results.txt":  
* "/mnt/d/" is the path;  
* "StorageXploreR_results" is the name;  
* "txt" is the extension.  
* "StorageXploreR_results.txt" is the full name.  

## Get file full name
To get file full names:
```{r get_fullnames}
full_names = get_fullnames(dataset[,2])
```

## Get name
To get file names:
```{r get_names}
names = get_names(full_names)
```

## Get file extension
To get file extensions ('.' is not included):
```{r get_extensions}
extensions = get_extensions(dataset[,2])
```

## Get file format
You can scan for file extensions belonging to formats recognized by the package:
```{r get_formats}
formats = get_formats(extensions)
```
To access the list file extensions and formats recognized by the package, type:
```{r load_knowndb}
data(known_db)

head(known_db)
```


# Redundancy detection
Data redundancy can come in two main forms: files with multiple copies and same data stored in different file formats. To have a more lean storage you may want to flag these for further inspection and possible removal.

## Detect files with multiple copies (criteria: same full name + same size + same md5sum)
Multi-copy files can be detected with:
```{r detect_multicopy, eval=FALSE}
multicopy_idx = detect_multicopy_files(dataset[,2], dataset[,1], use_md5sum=FALSE)
```
Because computing md5sums can be computationally heavy, their usage is deactivated by default. However, it is therefore advised to check them to guarantee that the files are true copies. 

## Detect related files (criteria: same name, but extension and size can differ)
Handling data can result in the exact same data stored under different file formats. For example, for security reasons we can get an encrypted file (.gpg), which after decryption can produce a new compressed file (.zip), which needs to be decompressed to get a readable version such as a vcf file (.vcf). This type of data flow frequently produces files that share the same name but vary in extension. Using this naming pattern allows to detect related instances.
This can be done via:
```{r detect_related, eval=FALSE}
related_idx = detect_related_files(full_names)
```


# Descriptive statistics
A set of functions to facilitate the computation of some basic statistics.
```{r descriptive_statistics, message=FALSE}
# Calculate number of files
#..by extension..
xt_tot = get_counts(extensions)
#..by format..
fm_tot = get_counts(formats)

# Calculate file sizes
#..by extension..
xt_sz = get_sizes(dataset[,1], extensions)
#..by format..
fm_sz = get_sizes(dataset[,1], formats)

# Calculate summary statistics for file size
#..by extension..
xt_summaries = get_summaries(dataset[,1], extensions)
#..by format..
fm_summaries = get_summaries(dataset[,1], formats)
```


# Plotting results
A set of functions were develop to quickly plot and visualize storage usage.
The functions allow to define the number of top categories to use in the plots, and can automatically detect and convert storage size units to improve visualization.

## Donut
The donut chart can be useful to get an impression about which files take the biggest fraction of the storage.
```{r plot_donut}
# Donut for storage usage by file extension
#..prepare data for plotting..
c_sz = xt_sz
names(c_sz) = colnames(dataset)[1]

#..plot..
plot_donut(sizes=c_sz, 
           tags=names(xt_sz),
		       fraction_thresh=0.02,
		       donut_title="Storage used by file extension")
```

## Barplot
The barplot allows to check which files take most of the storage. In a donut chart we focus on fractions, here we focus on total size taken. Plotting side-by-side can give a better impression about the categories plotted relative to each other. 
```{r plot_barplot}
# Barplot for top file extensions in terms of storage usage
plot_barplot(sizes=c_sz,
             tags=names(xt_sz),
             max_tags=20,
             barplot_title="Size in storage",
             x_label="File Extension")
```

## Boxplot
The barplot allows to get an overview for individual files. Prioritizing outliers in downstream storage optimization can be an easy way to quickly gain storage space.
```{r plot_boxplot}
# Boxplot for all files in file extension groups with top storage usage
c_sz = dataset[,1]
names(c_sz) = colnames(dataset)[1]

plot_boxplot(sizes=c_sz,
             tags=extensions,
             max_tags=20,
             boxplot_title="File size",
             x_label="File Extension")
```




